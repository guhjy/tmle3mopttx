<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Ivana Malenica, Jeremy R. Coyle" />

<meta name="date" content="2018-10-10" />

<title>Variable Importance with Optimal Individualized Categorical Treatment</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Variable Importance with Optimal Individualized Categorical Treatment</h1>
<h4 class="author"><em><a href="https://github.com/podTockom">Ivana Malenica</a>, <a href="https://github.com/jeremyrcoyle">Jeremy R. Coyle</a></em></h4>
<h4 class="date"><em>2018-10-10</em></h4>



<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>Suppose one wishes to maximize (or minimize) the population mean of an outcome using a categorical point treatment, where for each individual one has access to measured baseline covariates. Such a treatment strategy is termed individualized treatment regime (ITR), and the (counterfactual) population mean outcome under an ITR is the value of the ITR. An ITR with the maximal (or minimal) value is referred to as an optimal ITR or the optimal rule, whereas the value of an optimal ITR is termed the optimal value. We consider estimation of the mean outcome under the optimal rule, where the candidate rules are restricted to depend only on user-supplied subset of the baseline covariates. The estimation problem is addressed in a statistical model for the data distribution that is nonparametric, and at most places restrictions on the probability of a patient receiving treatment given covariates. Finally, we extend ideas explored by Luedtke et. al to cover ITRs with categorical treatment. For additional background on Targeted Learning and previous work on optimal individualized treatment regimes, please consider consulting <span class="citation">Mark J van der Laan and Rose (2011)</span>, <span class="citation">Mark J van der Laan and Rose (2018)</span>, <span class="citation">Laan and Luedtke (2015)</span> and <span class="citation">A. Luedtke and Laan (2016)</span>.</p>
<p>To start, let’s load the packages we’ll use and set a seed for simulation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(data.table)
<span class="kw">library</span>(here)
<span class="kw">library</span>(sl3)
<span class="kw">library</span>(tmle3)
<span class="kw">library</span>(tmle3mopttx)
<span class="kw">set.seed</span>(<span class="dv">111</span>)</code></pre></div>
<hr />
</div>
<div id="data-and-notation" class="section level2">
<h2>Data and Notation</h2>
<p>Suppose we observe <span class="math inline">\(n\)</span> i.i.d. observations of <span class="math inline">\(O=(W,A,Y) \sim P_0\)</span>. We denote <span class="math inline">\(A\)</span> as treatment, where <span class="math inline">\(A \in \{0,1\}\)</span> and <span class="math inline">\(Y\)</span> is the final outcome. Note that we treat <span class="math inline">\(W\)</span> as all of our collected baseline covariates. We emphasize that we make no assumptions about the distribution of <span class="math inline">\(P_0\)</span>, so that <span class="math inline">\(P_0 \in \mathcal{M}\)</span>, where <span class="math inline">\(\mathcal{M}\)</span> is the fully nonparametric model. This is in contrast to much of the current literature that relies on parametric assumptions. We can break the data generating distribution <span class="math inline">\(P_0\)</span> into the following parts:</p>
<p><span class="math display">\[P_0(O) = P_0(Y|A,W)P_0(A|W)P_0(W) = Q_0(Y|A,W)g_0(A|W)Q_{W,0}(W)\]</span> In addition, we also define <span class="math inline">\(\bar{Q}_{Y,0}(A,W) \equiv E_0[Y|A,W]\)</span> such that <span class="math inline">\(E_0(Y_a) = E_{0,W}(\bar{Q}_{Y,0}(A=a,W))\)</span>.</p>
<div id="simulated-data" class="section level3">
<h3>Simulated Data</h3>
<p>First, we load the simulated data. Here, our data generating distribution was of the following form:</p>
<p><span class="math display">\[W_1,W_2,W_3,W_4,W_5 \sim \mathcal{N}(0,1)\]</span> <span class="math display">\[P(A=a_i|W) \sim \frac{\text{logit}^{-1}(W_i)} {\sum_{i=1}^3 \text{logit}^{-1}(W_i)} \]</span> <span class="math display">\[P(Y=1|A,W) = \frac{1}{2} \text{logit}^{-1}[-5 I(A=a_2)(W_1-\frac{1}{2}) + 5I(A=a_3)(W_1 - \frac{1}{2})] + \frac{1}{2}\text{logit}^{-1}(W_2W_3)\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">load</span>(<span class="kw">here</span>(<span class="st">&quot;data/test_vim_cat_data.rda&quot;</span>))</code></pre></div>
<p>The above composes our observed data structure <span class="math inline">\(O = (W, A, Y)\)</span>. To formally express this fact using the <code>tlverse</code> grammar introduced by the <code>tmle3</code> package, we create a single data object and specify the functional relationships between the nodes in the <em>directed acyclic graph</em> (DAG) via <em>nonparametric structural equation models</em> (NPSEMs), reflected in the node list that we set up:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># organize data and nodes for tmle3</span>
data &lt;-<span class="st"> </span>test_vim_cat_data
node_list &lt;-<span class="st"> </span><span class="kw">list</span>(
  <span class="dt">W =</span> <span class="kw">c</span>(<span class="st">&quot;W1&quot;</span>, <span class="st">&quot;W2&quot;</span>, <span class="st">&quot;W3&quot;</span>, <span class="st">&quot;W4&quot;</span>, <span class="st">&quot;W5&quot;</span>),
  <span class="dt">A =</span> <span class="st">&quot;A&quot;</span>,
  <span class="dt">Y =</span> <span class="st">&quot;Y&quot;</span>
)</code></pre></div>
<p>We now have an observed data structure (<code>data</code>) and a specification of the role that each variable in the data set plays as the nodes in a DAG.</p>
<hr />
</div>
</div>
<div id="methodology" class="section level2">
<h2>Methodology</h2>
<p>Many methods for learning an optimal rule from data have been developed. Here, we focus on the methods developed in <span class="citation">A. Luedtke and Laan (2016)</span> and <span class="citation">Laan and Luedtke (2015)</span>; however <code>tmle3mopttx</code> also supports the widely used Q-learning approach, based on generating an estimate of <span class="math inline">\(\bar{Q}_{Y,0}(A,W)\)</span> <span class="citation">(<span class="citeproc-not-found" data-reference-id="Sutton1998"><strong>???</strong></span>)</span>.</p>
<p>In particular, <span class="citation">A. Luedtke and Laan (2016)</span> and <span class="citation">Laan and Luedtke (2015)</span> outline a methodology for learning an optimal ITR using Super Learner <span class="citation">Mark J. van der Laan, Polley, and Hubbard (2007)</span>, and estimating its value using the cross-validated Targeted Minimum Loss-based Estimation (CV-TMLE) <span class="citation">Zheng and van der Laan (2010)</span>. Luedtke and van der Laan present three different appraches for leaning optimal rule, but <code>tmle3mopttx</code> relies on using the Super Learner to estimate the blip function (or “pseudo-blip” for categorical treatment).</p>
<p>In great generality, we first need to estimate an individual treatment regime which corresponds to dynamic treatment rule (<span class="math inline">\(d(V)\)</span>) that takes a subset of covariates <span class="math inline">\(V \in W\)</span> and assigns treatment. As specified in the introduction, we are also interested in the value of such a dynamic rule: <span class="math display">\[E_0[Y_{d(V)}] = E_{0,W}[\bar{Q}_{Y,0}(A=d(V),W)]\]</span> which, under causal assumptions, can be interpreted as the mean outcome if (possibly contrary to fact), treatment was assigned according to the rule. The optimal rule is the rule with the maximal value: <span class="math display">\[d_0 \equiv \text{argmax}_{d \in \mathcal{D}} E_0[Y_{d(V)}] \]</span> where <span class="math inline">\(\mathcal{D}\)</span> represents the set of possible rules, <span class="math inline">\(d\)</span>.</p>
<div id="binary-treatment" class="section level3">
<h3>Binary treatment</h3>
<p>In the case of a binary treatment, a key quantity for optimal ITR is the blip function. In particular, one can show that any optimal ITR assigns treatment to individuals falling in strata in which the stratum specific average treatment effect, the blip function, is positive and does not assign treatment to individuals for which this quantity is negative. Therefore for a binary treatment, we define a blip function as <span class="math display">\[E_0[Y_1-Y_0|V] \equiv E_0[\bar{Q}_{Y,0}(1,W) - \bar{Q}_{Y,0}(0,W) | V] \]</span> The note that the rule can now be derived as <span class="math inline">\(d_0(V) = I(\bar{Q}_0(V) &gt; 0)\)</span>.</p>
<p>In particular, we will:</p>
<ol style="list-style-type: decimal">
<li><p>Estimate <span class="math inline">\(\bar{Q}_{Y,0}(A,W)\)</span> and <span class="math inline">\(g_0(A|W)\)</span> using <code>sl3</code>.</p></li>
<li><p>Apply the doubly robust A-IPW transform to our outcome, where we define:</p></li>
</ol>
<p><span class="math display">\[D_{\bar{Q},g,a}(O) \equiv \frac{I(A=a)}{g(A|W)} (Y-\bar{Q}_Y(A,W)) + \bar{Q}_Y(A=a,W),\]</span> <span class="math display">\[E(D_{\bar{Q},g,a}(O) | V) = E(Y^a|V).\]</span> Using this transform, we can define the following contrast: <span class="math inline">\(D_{\bar{Q},g}(O) = D_{\bar{Q},g,a=1}(O) - D_{\bar{Q},g,a=0}(O)\)</span></p>
<p>We estimate the blip function ({Q}_{0,a}(V)) by regressing <span class="math inline">\(D_{\bar{Q},g}(O)\)</span> on <span class="math inline">\(V\)</span> using <code>sl3</code>.</p>
<ol start="3" style="list-style-type: decimal">
<li><p>Our estimated rule is <span class="math inline">\(d(V) = \text{argmax}_{a \in \mathcal{A}} \bar{Q}_{0,a}(V)\)</span>.</p></li>
<li><p>Inference for the mean outcome under the optimal rule using CV-TMLE.</p></li>
</ol>
</div>
<div id="categorical-treatment" class="section level3">
<h3>Categorical treatment</h3>
<p>In line with the approach considered for binary treatment, we extend the blip function apprach to allow for categorical treatment by estimating “pseudo-blips”. We define pseudo-blips as vector valued entities where the output for a given <span class="math inline">\(V\)</span> is a vector of length equal to the number of treatment categories. As such, we define it as: <span class="math display">\[\bar{Q}_0^{pblip}(V) = \{\bar{Q}_{0,a}^{pblip}(V): a \in \mathcal{A} \}\]</span> We implement three different pseudo-blips in <code>tmle3mopttx</code>.</p>
<ol style="list-style-type: decimal">
<li><p>“Blip1” corresponds to choosing a reference category of treatment, and defining the blip for all other categories relative to the specified reference. Hence we have that: <span class="math display">\[\bar{Q}_{0,a}^{pblip-ref}(V) \equiv E_0(Y_a-Y-0|V)\]</span> where <span class="math inline">\(Y_0\)</span> is the specified reference category. Note that, for the case of binary treatment, this strategy reduces to the apparoach described in the previous section.</p></li>
<li>“Blip2” approach corresponds to defining the blip relative to the average of all categories. As such, we can define <span class="math inline">\(\bar{Q}_{0,a}^{pblip-avg}(V)\)</span> as: <span class="math display">\[\bar{Q}_{0,a}^{pblip-avg}(V) \equiv E_0(Y_a- \frac{1}{n_A} \sum_{a^{'} \in \mathcal{A}} Y_{a^{'}}|V)\]</span></li>
<li><p>“Blip3” reflects an extension of “Blip2”, where the average is now a weighted average. <span class="math display">\[\bar{Q}_{0,a}^{pblip-wavg}(V) \equiv E_0(Y_a- \frac{1}{n_A} \sum_{a^{'} \in \mathcal{A}} P(A=a^{'}|V)
Y_{a^{'}}|V)\]</span></p></li>
</ol>
<p>Just like in the binary case, pseudo-blips are estimated by regressing contrasts composed using the A-IPW transform on <span class="math inline">\(V\)</span>.</p>
</div>
<div id="computational-considerations" class="section level3">
<h3>Computational Considerations</h3>
<p>We use the estimation approach outlined in <span class="citation">A. Luedtke and Laan (2016)</span> and <span class="citation">Laan and Luedtke (2015)</span>, which makes frequent use of cross-validation for both model selection and CV-TMLE based parameter estimation <span class="citation">Zheng and van der Laan (2010)</span>. In order to avoid nesting cross-validation, <code>tmle3mopptx</code> relies on Split-Specific Super Learner in order to estimate the rule, as described by Coyle et al <span class="citation">(Coyle 2017)</span>.</p>
</div>
<div id="interlude-constructing-optimal-stacked-regressions-with-sl3" class="section level3">
<h3><em>Interlude:</em> Constructing Optimal Stacked Regressions with <code>sl3</code></h3>
<p>To easily incorporate ensemble machine learning into the estimation procedure, we rely on the facilities provided in the <a href="https://sl3.tlverse.org"><code>sl3</code> R package</a>. For a complete guide on using the <code>sl3</code> R package, consider consulting <a href="https://sl3.tlverse.org" class="uri">https://sl3.tlverse.org</a>, or <a href="https://tlverse.org" class="uri">https://tlverse.org</a> for the <a href="https://github.com/tlverse"><code>tlverse</code> ecosystem</a>, of which <code>sl3</code> is a major part.</p>
<p>Using the framework provided by the <a href="https://sl3.tlverse.org"><code>sl3</code> package</a>, the nuisance parameters of the TML estimator may be fit with ensemble learning, using the cross-validation framework of the Super Learner algorithm of <span class="citation">Mark J. van der Laan, Polley, and Hubbard (2007)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Define sl3 library and metalearners:</span>
qlib &lt;-<span class="st"> </span><span class="kw">make_learner_stack</span>(
  <span class="st">&quot;Lrnr_mean&quot;</span>,
  <span class="st">&quot;Lrnr_glm_fast&quot;</span>
)

glib &lt;-<span class="st"> </span><span class="kw">make_learner_stack</span>(
  <span class="st">&quot;Lrnr_mean&quot;</span>,
  <span class="st">&quot;Lrnr_glmnet&quot;</span>,
  <span class="st">&quot;Lrnr_xgboost&quot;</span>
)

blib &lt;-<span class="st"> </span><span class="kw">make_learner_stack</span>(
  <span class="st">&quot;Lrnr_glm_fast&quot;</span>,
  <span class="st">&quot;Lrnr_xgboost&quot;</span>
)

metalearner &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_nnls)
mn_metalearner &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_solnp, <span class="dt">loss_function =</span> loss_loglik_multinomial, <span class="dt">learner_function =</span> metalearner_linear_multinomial)

Q_learner &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_sl, qlib, metalearner)
g_learner &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_sl, glib, mn_metalearner)
b_learner &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_sl, blib, metalearner)</code></pre></div>
<p>As seen above, we generate three different ensemble learners that must be fit, corresponding to the learners for the outcome regression, propensity score, and the blip function. Note that we need to estimate <span class="math inline">\(g_0(A|W)\)</span> for a categorical <span class="math inline">\(A\)</span>- therefore we use the multinomial Super Learner option available within the <code>sl3</code> package with learners that can address multi-class classification problems. In order to see which learners can be used to estimate <span class="math inline">\(g_0(A|W)\)</span> in <code>sl3</code>, we run the following:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#See which learners support multi-class classification:</span>
<span class="kw">sl3_list_learners</span>(<span class="kw">c</span>(<span class="st">&quot;categorical&quot;</span>))</code></pre></div>
<pre><code>##  [1] &quot;Lrnr_bartMachine&quot;          &quot;Lrnr_dbarts&quot;              
##  [3] &quot;Lrnr_glmnet&quot;               &quot;Lrnr_grf&quot;                 
##  [5] &quot;Lrnr_h2o_glm&quot;              &quot;Lrnr_h2o_grid&quot;            
##  [7] &quot;Lrnr_independent_binomial&quot; &quot;Lrnr_mean&quot;                
##  [9] &quot;Lrnr_optim&quot;                &quot;Lrnr_randomForest&quot;        
## [11] &quot;Lrnr_ranger&quot;               &quot;Lrnr_rpart&quot;               
## [13] &quot;Lrnr_solnp&quot;                &quot;Lrnr_svm&quot;                 
## [15] &quot;Lrnr_xgboost&quot;</code></pre>
<p>We make the above explicit with respect to standard notation by bundling the ensemble learners into a list object below:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># specify outcome and treatment regressions and create learner list</span>
learner_list &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">Y =</span> Q_learner, <span class="dt">A =</span> g_learner, <span class="dt">B =</span> b_learner)</code></pre></div>
<p>The <code>learner_list</code> object above specifies the role that each of the ensemble learners we’ve generated is to play in computing initial estimators to be used in building a TMLE for the parameter of interest here. In particular, it makes explicit the fact that our <code>Y</code> is used in fitting the outcome regression while our <code>A</code> is used in fitting our treatment mechanism regression, and finally <code>B</code> is used in fitting the blip function.</p>
</div>
<div id="initializing-tmle3mopttx-through-its-tmle3_spec" class="section level3">
<h3>Initializing <code>tmle3mopttx</code> through its <code>tmle3_Spec</code></h3>
<p>To start, we will initialize a specification for the TMLE of our parameter of interest (called a <code>tmle3_Spec</code> in the <code>tlverse</code> nomenclature) simply by calling <code>tmle3_mopttx</code>. We specify the argument <code>shift_grid = seq(-0.5, 0.5, by = 0.5)</code> when initializing the <code>tmle3_Spec</code> object to communicate that we’re interested in assessing the mean counterfactual outcome over a grid of shifts -0.5, 0, 0.5 on the scale of the treatment <span class="math inline">\(A\)</span> (note that the numerical choice of shift is an arbitrarily chosen set of values for this example).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># initialize a tmle specification</span>
tmle_spec &lt;-<span class="st"> </span><span class="kw">tmle3_mopttx</span>(<span class="dt">V =</span> <span class="kw">c</span>(<span class="st">&quot;W1&quot;</span>, <span class="st">&quot;W2&quot;</span>, <span class="st">&quot;W3&quot;</span>, <span class="st">&quot;W4&quot;</span>, <span class="st">&quot;W5&quot;</span>), <span class="dt">type =</span> <span class="st">&quot;blip2&quot;</span>, <span class="dt">b_learner =</span> learner_list<span class="op">$</span>B)</code></pre></div>
<p>As seen above, the <code>tmle_mopttx</code> specification object (like all <code>tmle3_Spec</code> objects) does <em>not</em> store the data for our specific analysis of interest. Later, we’ll see that passing a data object directly to the <code>tmle3</code> wrapper function, alongside the instantiated <code>tmle_spec</code>, will serve to construct a <code>tmle3_Task</code> object internally (see the <code>tmle3</code> documentation for details).</p>
<p>In initializing the specification for the TMLE of our parameter of interest, we have specified the set of covariates the rule depends on (<span class="math inline">\(V\)</span>), the type of pseudo-blip to use (“type”), and the learners used for estimating the pseudo-blip.</p>
</div>
<div id="targeted-estimation-of-the-mean-under-the-optimal-itr" class="section level3">
<h3>Targeted Estimation of the Mean under the optimal ITR</h3>
<p>One may walk through the step-by-step procedure for fitting the TML estimator of the mean counterfactual outcome under the optimal ITR, using the machinery exposed by the <a href="https://tmle3.tlverse.org/"><code>tmle3</code> R package</a> (see below); however, the step-by-step procedure is often not of interest.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># NOT RUN -- SEE NEXT CODE CHUNK</span>

<span class="co"># Define data:</span>
tmle_task &lt;-<span class="st"> </span>tmle_spec<span class="op">$</span><span class="kw">make_tmle_task</span>(data, node_list)

<span class="co"># Define likelihood:</span>
initial_likelihood &lt;-<span class="st"> </span>tmle_spec<span class="op">$</span><span class="kw">make_initial_likelihood</span>(tmle_task, learner_list)

<span class="co"># Learn the rule:</span>
opt_rule &lt;-<span class="st"> </span>Optimal_Rule<span class="op">$</span><span class="kw">new</span>(tmle_task, initial_likelihood, <span class="st">&quot;split-specific&quot;</span>,
  <span class="dt">blip_library =</span> learner_list<span class="op">$</span>B,
  <span class="dt">blip_type =</span> tmle_spec<span class="op">$</span>options<span class="op">$</span>type
)
opt_rule<span class="op">$</span><span class="kw">fit_blip</span>()

<span class="co"># Define a dynamic likelihood factor:</span>
lf_rule &lt;-<span class="st"> </span><span class="kw">define_lf</span>(LF_rule, <span class="st">&quot;A&quot;</span>, <span class="dt">rule_fun =</span> opt_rule<span class="op">$</span>rule)

<span class="co"># Define updater and targeted likelihood:</span>
updater &lt;-<span class="st"> </span>tmle3_cv_Update<span class="op">$</span><span class="kw">new</span>()
targeted_likelihood &lt;-<span class="st"> </span>Targeted_Likelihood<span class="op">$</span><span class="kw">new</span>(initial_likelihood, updater)

tsm_rule &lt;-<span class="st"> </span>Param_TSM<span class="op">$</span><span class="kw">new</span>(targeted_likelihood, lf_rule)

updater<span class="op">$</span>tmle_params &lt;-<span class="st"> </span>tsm_rule
tmle_fit &lt;-<span class="st"> </span><span class="kw">fit_tmle3</span>(tmle_task, targeted_likelihood, <span class="kw">list</span>(tsm_rule), updater)

<span class="co"># extract results</span>
tmle3_psi &lt;-<span class="st"> </span>tmle_fit<span class="op">$</span>summary<span class="op">$</span>tmle_est</code></pre></div>
<p>Instead, one may invoke the <code>tmle3</code> convenience function to fit the series of TML estimators in a single function call:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># fit the TML estimator</span>
fit &lt;-<span class="st"> </span><span class="kw">tmle3</span>(tmle_spec, data, node_list, learner_list)
fit</code></pre></div>
<p><em>Remark</em>: The <code>print</code> method of the resultant <code>tmle_fit</code> object conveniently displays the results from computing our TML estimator.</p>
</div>
</div>
<div id="references" class="section level2 unnumbered">
<h2>References</h2>
<div id="refs" class="references">
<div id="ref-jeremythesis">
<p>Coyle, Jeremy R. 2017. “Computational Considerations for Targeted Learning.” PhD thesis, U.C. Berkeley.</p>
</div>
<div id="ref-vanderLaanLuedtke15">
<p>Laan, M.J. van der, and A. Luedtke. 2015. “Targeted Learning of the Mean Outcome Under an Optimal Dynamic Treatment Rule.” <em>Journal of Causal Inference</em> 3 (1): 61–95.</p>
</div>
<div id="ref-luedtke2016super">
<p>Luedtke, A.R., and M.J. van der Laan. 2016. “Super-Learning of an Optimal Dynamic Treatment Rule.” <em>International Journal of Biostatistics</em> 12 (1): 305–32.</p>
</div>
<div id="ref-vdl2011targeted">
<p>van der Laan, Mark J, and Sherri Rose. 2011. <em>Targeted Learning: Causal Inference for Observational and Experimental Data</em>. Springer Science &amp; Business Media.</p>
</div>
<div id="ref-vdl2018targeted">
<p>———. 2018. <em>Targeted Learning in Data Science: Causal Inference for Complex Longitudinal Studies</em>. Springer Science &amp; Business Media.</p>
</div>
<div id="ref-vdl2007super">
<p>van der Laan, Mark J., Eric C. Polley, and Alan E. Hubbard. 2007. “Super Learner.” <em>Statistical Applications in Genetics and Molecular Biology</em> 6 (1).</p>
</div>
<div id="ref-cvtmle2010">
<p>Zheng, W., and M. J van der Laan. 2010. “Asymptotic Theory for Cross-validated Targeted Maximum Likelihood Estimation.” <em>U.C. Berkeley Division of Biostatistics Working Paper Series.</em></p>
</div>
</div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
